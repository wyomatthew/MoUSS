{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CU6MKFIfpeT",
        "outputId": "141444a9-a0ea-443f-c235-bd5730375e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXFCQXwKfsu5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from zipfile import ZipFile\n",
        "from itertools import count\n",
        "from scipy.spatial import distance_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zek73zRpfs6P"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_Y9jfs-ftCJ"
      },
      "outputs": [],
      "source": [
        "submissions = \"/content/drive/MyDrive/CIS 5450/submissions_cleaned.csv\"\n",
        "reddit = pd.read_csv(submissions, parse_dates=[\"created\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5186g_zhEQs"
      },
      "source": [
        "# **Classification of Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac8sZ88zftHe",
        "outputId": "880abad2-7d9c-40c2-fcc7-7d100032095a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "381664"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(reddit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIhs3RaGftLK",
        "outputId": "cd5288d0-baca-4008-df7e-705a3fbca755"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.downloader.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_xkJVAEftNu"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJoW30vRhyju"
      },
      "outputs": [],
      "source": [
        "df_posts = reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIWgdkk4ftQy"
      },
      "outputs": [],
      "source": [
        "#get the polarity scores of the text \n",
        "df_posts['score'] = df_posts['text'].apply(lambda text: sid.polarity_scores(str(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qN8sdX-ftTN"
      },
      "outputs": [],
      "source": [
        "#get the compounded scores from the score column\n",
        "df_posts['compound']  = df_posts['score'].apply(lambda score_dict: score_dict['compound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHeqcru7ftWU"
      },
      "outputs": [],
      "source": [
        "#use compound scores to perform a ranking on the sentiment in 3 categories, positive, negative\n",
        "df_posts['sentiment'] = df_posts['compound'].apply(lambda c: 'positive' if c > 0 else('negative' if c < 0 else 'neutral'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HUHn-i6ftZw",
        "outputId": "61d73cf7-9001-4438-a731-83c319c5f9c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                         int64\n",
              "subreddit_name            object\n",
              "text                      object\n",
              "author_name               object\n",
              "score                     object\n",
              "up_votes                   int64\n",
              "down_votes                 int64\n",
              "created           datetime64[ns]\n",
              "awards                    object\n",
              "url                       object\n",
              "compound                 float64\n",
              "sentiment                 object\n",
              "dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_posts.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djPCnP7Eftcv"
      },
      "outputs": [],
      "source": [
        "#isolate only core columns and proceed\n",
        "posts = df_posts[['subreddit_name', 'text', 'sentiment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NnGz64AtftgQ",
        "outputId": "fdb451dd-edd7-45ec-c6ac-590e3c083363"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9870545a-91c3-41c9-a3cf-7e191505091e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subreddit_name</th>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">berkeley</th>\n",
              "      <th>negative</th>\n",
              "      <td>14562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>12515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>27140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">brownu</th>\n",
              "      <th>negative</th>\n",
              "      <td>1631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>2344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>8398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">caltech</th>\n",
              "      <th>negative</th>\n",
              "      <td>449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>3200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">cmu</th>\n",
              "      <th>negative</th>\n",
              "      <td>3698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>4536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>14011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">columbia</th>\n",
              "      <th>negative</th>\n",
              "      <td>5311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>14049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">cornell</th>\n",
              "      <th>negative</th>\n",
              "      <td>3554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>2307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>5629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">dartmouth</th>\n",
              "      <th>negative</th>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>6119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">gatech</th>\n",
              "      <th>negative</th>\n",
              "      <td>12332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>11135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>25951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">harvard</th>\n",
              "      <th>negative</th>\n",
              "      <td>3121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>4322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>11682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">mit</th>\n",
              "      <th>negative</th>\n",
              "      <td>2846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>10893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">princeton</th>\n",
              "      <th>negative</th>\n",
              "      <td>1134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>5594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">stanford</th>\n",
              "      <th>negative</th>\n",
              "      <td>3170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>3993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>12391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">uchicago</th>\n",
              "      <th>negative</th>\n",
              "      <td>4357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>14964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">uiuc</th>\n",
              "      <th>negative</th>\n",
              "      <td>13266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>12674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>25287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">upenn</th>\n",
              "      <th>negative</th>\n",
              "      <td>4264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>5447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>12886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">yale</th>\n",
              "      <th>negative</th>\n",
              "      <td>2009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>2377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>8087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9870545a-91c3-41c9-a3cf-7e191505091e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9870545a-91c3-41c9-a3cf-7e191505091e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9870545a-91c3-41c9-a3cf-7e191505091e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                           text\n",
              "subreddit_name sentiment       \n",
              "berkeley       negative   14562\n",
              "               neutral    12515\n",
              "               positive   27140\n",
              "brownu         negative    1631\n",
              "               neutral     2344\n",
              "               positive    8398\n",
              "caltech        negative     449\n",
              "               neutral      747\n",
              "               positive    3200\n",
              "cmu            negative    3698\n",
              "               neutral     4536\n",
              "               positive   14011\n",
              "columbia       negative    5311\n",
              "               neutral     5425\n",
              "               positive   14049\n",
              "cornell        negative    3554\n",
              "               neutral     2307\n",
              "               positive    5629\n",
              "dartmouth      negative    1002\n",
              "               neutral     1808\n",
              "               positive    6119\n",
              "gatech         negative   12332\n",
              "               neutral    11135\n",
              "               positive   25951\n",
              "harvard        negative    3121\n",
              "               neutral     4322\n",
              "               positive   11682\n",
              "mit            negative    2846\n",
              "               neutral     3347\n",
              "               positive   10893\n",
              "princeton      negative    1134\n",
              "               neutral     1775\n",
              "               positive    5594\n",
              "stanford       negative    3170\n",
              "               neutral     3993\n",
              "               positive   12391\n",
              "uchicago       negative    4357\n",
              "               neutral     5144\n",
              "               positive   14964\n",
              "uiuc           negative   13266\n",
              "               neutral    12674\n",
              "               positive   25287\n",
              "upenn          negative    4264\n",
              "               neutral     5447\n",
              "               positive   12886\n",
              "yale           negative    2009\n",
              "               neutral     2377\n",
              "               positive    8087"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_posts[\"sentiment\"].unique()\n",
        "posts.groupby(['subreddit_name', 'sentiment']).nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmbiRwbEiH5H"
      },
      "source": [
        "# **Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pinB1qAeftij"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnMpM9fUiM6X"
      },
      "outputs": [],
      "source": [
        "smaller_df = posts[['subreddit_name','text', 'sentiment']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCr3JoCGimid"
      },
      "source": [
        "# **Cluster 1 - Upenn, Columbia, Uchicago**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr4QFylJjA6o",
        "outputId": "45f529a1-2e82-4c5c-adcc-f9d3d175ffe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['upenn', 'princeton', 'mit', 'harvard', 'stanford', 'yale',\n",
              "       'uchicago', 'caltech', 'brownu', 'columbia', 'cornell',\n",
              "       'dartmouth', 'cmu', 'uiuc', 'berkeley', 'gatech'], dtype=object)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "posts['subreddit_name'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OvEz3d-iP7m"
      },
      "outputs": [],
      "source": [
        "penn = posts.loc[posts['subreddit_name'] == 'upenn']\n",
        "columbia = posts.loc[posts['subreddit_name'] == 'columbia']\n",
        "uchicago = posts.loc[posts['subreddit_name'] == 'uchicago']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDkWmLEhjnLy"
      },
      "source": [
        "# A. Upenn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81MdFsVxiQHG"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(penn['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXpqGhB4iQP3",
        "outputId": "7b23892e-2b1f-4c04-8a23-d4225b4b46da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ... 1966 4018  872]\n",
            " [   0    0    0 ...   69  134 3312]\n",
            " [   0    0    0 ...    0   16    9]\n",
            " ...\n",
            " [   0    0    0 ...  580   75  229]\n",
            " [   0    0    0 ...  482  414 2907]\n",
            " [   0    0    0 ...  504 1068  101]]\n",
            "17725 5909 17725 5909\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(penn[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(penn[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy2re9qMiQWW",
        "outputId": "1383280a-39fc-4b90-e126-7e7371b62337"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.7789 - accuracy: 0.6623\n",
            "Epoch 1: val_accuracy improved from -inf to 0.73532, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 120s 150ms/step - loss: 0.7789 - accuracy: 0.6623 - val_loss: 0.6379 - val_accuracy: 0.7353\n",
            "Epoch 2/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7621\n",
            "Epoch 2: val_accuracy improved from 0.73532 to 0.77932, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 81s 147ms/step - loss: 0.5782 - accuracy: 0.7621 - val_loss: 0.5447 - val_accuracy: 0.7793\n",
            "Epoch 3/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8128\n",
            "Epoch 3: val_accuracy improved from 0.77932 to 0.81469, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 84s 151ms/step - loss: 0.4859 - accuracy: 0.8128 - val_loss: 0.4694 - val_accuracy: 0.8147\n",
            "Epoch 4/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.8348\n",
            "Epoch 4: val_accuracy improved from 0.81469 to 0.83347, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 83s 151ms/step - loss: 0.4285 - accuracy: 0.8348 - val_loss: 0.4300 - val_accuracy: 0.8335\n",
            "Epoch 5/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3826 - accuracy: 0.8586\n",
            "Epoch 5: val_accuracy improved from 0.83347 to 0.84786, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 82s 147ms/step - loss: 0.3826 - accuracy: 0.8586 - val_loss: 0.4129 - val_accuracy: 0.8479\n",
            "Epoch 6/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8658\n",
            "Epoch 6: val_accuracy improved from 0.84786 to 0.85446, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 84s 151ms/step - loss: 0.3607 - accuracy: 0.8658 - val_loss: 0.3898 - val_accuracy: 0.8545\n",
            "Epoch 7/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3345 - accuracy: 0.8795\n",
            "Epoch 7: val_accuracy improved from 0.85446 to 0.86461, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 81s 147ms/step - loss: 0.3345 - accuracy: 0.8795 - val_loss: 0.3800 - val_accuracy: 0.8646\n",
            "Epoch 8/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8853\n",
            "Epoch 8: val_accuracy improved from 0.86461 to 0.87155, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 83s 151ms/step - loss: 0.3197 - accuracy: 0.8853 - val_loss: 0.3797 - val_accuracy: 0.8716\n",
            "Epoch 9/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8909\n",
            "Epoch 9: val_accuracy did not improve from 0.87155\n",
            "554/554 [==============================] - 81s 147ms/step - loss: 0.3046 - accuracy: 0.8909 - val_loss: 0.3949 - val_accuracy: 0.8655\n",
            "Epoch 10/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8960\n",
            "Epoch 10: val_accuracy improved from 0.87155 to 0.87680, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 84s 151ms/step - loss: 0.2956 - accuracy: 0.8960 - val_loss: 0.3685 - val_accuracy: 0.8768\n",
            "Epoch 11/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9014\n",
            "Epoch 11: val_accuracy improved from 0.87680 to 0.87849, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 83s 150ms/step - loss: 0.2861 - accuracy: 0.9014 - val_loss: 0.3677 - val_accuracy: 0.8785\n",
            "Epoch 12/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.9035\n",
            "Epoch 12: val_accuracy improved from 0.87849 to 0.88069, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 82s 147ms/step - loss: 0.2806 - accuracy: 0.9035 - val_loss: 0.3550 - val_accuracy: 0.8807\n",
            "Epoch 13/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2700 - accuracy: 0.9090\n",
            "Epoch 13: val_accuracy did not improve from 0.88069\n",
            "554/554 [==============================] - 81s 146ms/step - loss: 0.2700 - accuracy: 0.9090 - val_loss: 0.3648 - val_accuracy: 0.8783\n",
            "Epoch 14/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.9097\n",
            "Epoch 14: val_accuracy did not improve from 0.88069\n",
            "554/554 [==============================] - 83s 150ms/step - loss: 0.2647 - accuracy: 0.9097 - val_loss: 0.3699 - val_accuracy: 0.8782\n",
            "Epoch 15/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.9126\n",
            "Epoch 15: val_accuracy improved from 0.88069 to 0.88137, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 82s 148ms/step - loss: 0.2629 - accuracy: 0.9126 - val_loss: 0.3575 - val_accuracy: 0.8814\n",
            "Epoch 16/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9122\n",
            "Epoch 16: val_accuracy did not improve from 0.88137\n",
            "554/554 [==============================] - 82s 148ms/step - loss: 0.2641 - accuracy: 0.9122 - val_loss: 0.3582 - val_accuracy: 0.8807\n",
            "Epoch 17/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.9127\n",
            "Epoch 17: val_accuracy improved from 0.88137 to 0.88441, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 83s 150ms/step - loss: 0.2590 - accuracy: 0.9127 - val_loss: 0.3470 - val_accuracy: 0.8844\n",
            "Epoch 18/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.9153\n",
            "Epoch 18: val_accuracy did not improve from 0.88441\n",
            "554/554 [==============================] - 81s 147ms/step - loss: 0.2532 - accuracy: 0.9153 - val_loss: 0.3492 - val_accuracy: 0.8844\n",
            "Epoch 19/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.9181\n",
            "Epoch 19: val_accuracy did not improve from 0.88441\n",
            "554/554 [==============================] - 83s 150ms/step - loss: 0.2482 - accuracy: 0.9181 - val_loss: 0.3574 - val_accuracy: 0.8827\n",
            "Epoch 20/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2466 - accuracy: 0.9188\n",
            "Epoch 20: val_accuracy did not improve from 0.88441\n",
            "554/554 [==============================] - 81s 146ms/step - loss: 0.2466 - accuracy: 0.9188 - val_loss: 0.3639 - val_accuracy: 0.8829\n",
            "Epoch 21/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2474 - accuracy: 0.9189\n",
            "Epoch 21: val_accuracy improved from 0.88441 to 0.88678, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 81s 146ms/step - loss: 0.2474 - accuracy: 0.9189 - val_loss: 0.3409 - val_accuracy: 0.8868\n",
            "Epoch 22/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.9199\n",
            "Epoch 22: val_accuracy improved from 0.88678 to 0.88729, saving model to best_model2.hdf5\n",
            "554/554 [==============================] - 83s 149ms/step - loss: 0.2446 - accuracy: 0.9199 - val_loss: 0.3562 - val_accuracy: 0.8873\n",
            "Epoch 23/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2452 - accuracy: 0.9184\n",
            "Epoch 23: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 83s 149ms/step - loss: 0.2452 - accuracy: 0.9184 - val_loss: 0.3558 - val_accuracy: 0.8863\n",
            "Epoch 24/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9209\n",
            "Epoch 24: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 81s 146ms/step - loss: 0.2398 - accuracy: 0.9209 - val_loss: 0.3579 - val_accuracy: 0.8836\n",
            "Epoch 25/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.9240\n",
            "Epoch 25: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 83s 149ms/step - loss: 0.2367 - accuracy: 0.9240 - val_loss: 0.3587 - val_accuracy: 0.8856\n",
            "Epoch 26/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.9220\n",
            "Epoch 26: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 80s 145ms/step - loss: 0.2363 - accuracy: 0.9220 - val_loss: 0.3724 - val_accuracy: 0.8820\n",
            "Epoch 27/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.9247\n",
            "Epoch 27: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 83s 149ms/step - loss: 0.2316 - accuracy: 0.9247 - val_loss: 0.3676 - val_accuracy: 0.8829\n",
            "Epoch 28/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.9229\n",
            "Epoch 28: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 81s 146ms/step - loss: 0.2362 - accuracy: 0.9229 - val_loss: 0.3627 - val_accuracy: 0.8832\n",
            "Epoch 29/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.9242\n",
            "Epoch 29: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 81s 145ms/step - loss: 0.2312 - accuracy: 0.9242 - val_loss: 0.3636 - val_accuracy: 0.8851\n",
            "Epoch 30/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.9245\n",
            "Epoch 30: val_accuracy did not improve from 0.88729\n",
            "554/554 [==============================] - 83s 149ms/step - loss: 0.2280 - accuracy: 0.9245 - val_loss: 0.3675 - val_accuracy: 0.8790\n"
          ]
        }
      ],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CZAcVQFiQel",
        "outputId": "b4e34220-ae90-48de-e20d-1ad01df1450b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 1.0047 - acc: 0.6292"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 23ms/step - loss: 1.0037 - acc: 0.6296 - val_loss: 0.7716 - val_acc: 0.7323\n",
            "Epoch 2/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.6929 - acc: 0.7616"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 21ms/step - loss: 0.6929 - acc: 0.7616 - val_loss: 0.6748 - val_acc: 0.7594\n",
            "Epoch 3/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.6202 - acc: 0.7814"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.6201 - acc: 0.7814 - val_loss: 0.6196 - val_acc: 0.7758\n",
            "Epoch 4/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.5799 - acc: 0.7954"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.5799 - acc: 0.7954 - val_loss: 0.6008 - val_acc: 0.7808\n",
            "Epoch 5/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.5585 - acc: 0.8073"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.5583 - acc: 0.8074 - val_loss: 0.5840 - val_acc: 0.7883\n",
            "Epoch 6/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.5418 - acc: 0.8128"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.5418 - acc: 0.8128 - val_loss: 0.5738 - val_acc: 0.7915\n",
            "Epoch 7/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.5299 - acc: 0.8188"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 21ms/step - loss: 0.5299 - acc: 0.8188 - val_loss: 0.5726 - val_acc: 0.8000\n",
            "Epoch 8/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.5199 - acc: 0.8247"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.5193 - acc: 0.8250 - val_loss: 0.5637 - val_acc: 0.7979\n",
            "Epoch 9/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.8243"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.5098 - acc: 0.8243 - val_loss: 0.5565 - val_acc: 0.8176\n",
            "Epoch 10/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4993 - acc: 0.8308"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.4993 - acc: 0.8308 - val_loss: 0.5484 - val_acc: 0.8061\n",
            "Epoch 11/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4875 - acc: 0.8359"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.4875 - acc: 0.8359 - val_loss: 0.5459 - val_acc: 0.8103\n",
            "Epoch 12/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.4734 - acc: 0.8413"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.4732 - acc: 0.8415 - val_loss: 0.5351 - val_acc: 0.8164\n",
            "Epoch 13/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4599 - acc: 0.8483"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.4599 - acc: 0.8483 - val_loss: 0.5334 - val_acc: 0.8243\n",
            "Epoch 14/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8604"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.4451 - acc: 0.8603 - val_loss: 0.5443 - val_acc: 0.8201\n",
            "Epoch 15/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.4238 - acc: 0.8711"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.4238 - acc: 0.8711 - val_loss: 0.5035 - val_acc: 0.8428\n",
            "Epoch 16/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3979 - acc: 0.8838"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3979 - acc: 0.8838 - val_loss: 0.4787 - val_acc: 0.8516\n",
            "Epoch 17/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.3785 - acc: 0.8917"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.3782 - acc: 0.8918 - val_loss: 0.4734 - val_acc: 0.8611\n",
            "Epoch 18/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8959"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3634 - acc: 0.8960 - val_loss: 0.4734 - val_acc: 0.8595\n",
            "Epoch 19/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.9022"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.3524 - acc: 0.9022 - val_loss: 0.4591 - val_acc: 0.8639\n",
            "Epoch 20/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.9045"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3424 - acc: 0.9045 - val_loss: 0.4449 - val_acc: 0.8663\n",
            "Epoch 21/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.3334 - acc: 0.9104"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3332 - acc: 0.9105 - val_loss: 0.4469 - val_acc: 0.8685\n",
            "Epoch 22/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3256 - acc: 0.9128"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 13s 24ms/step - loss: 0.3256 - acc: 0.9128 - val_loss: 0.4463 - val_acc: 0.8670\n",
            "Epoch 23/30\n",
            "552/554 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.9167"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3165 - acc: 0.9167 - val_loss: 0.4444 - val_acc: 0.8653\n",
            "Epoch 24/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3090 - acc: 0.9202"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.3090 - acc: 0.9202 - val_loss: 0.4466 - val_acc: 0.8683\n",
            "Epoch 25/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.3026 - acc: 0.9221"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.3026 - acc: 0.9221 - val_loss: 0.4453 - val_acc: 0.8673\n",
            "Epoch 26/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.9256"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.2944 - acc: 0.9254 - val_loss: 0.4537 - val_acc: 0.8690\n",
            "Epoch 27/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.9291"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 25ms/step - loss: 0.2880 - acc: 0.9291 - val_loss: 0.4578 - val_acc: 0.8639\n",
            "Epoch 28/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2821 - acc: 0.9313"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.2821 - acc: 0.9313 - val_loss: 0.4504 - val_acc: 0.8644\n",
            "Epoch 29/30\n",
            "554/554 [==============================] - ETA: 0s - loss: 0.2763 - acc: 0.9340"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 14s 26ms/step - loss: 0.2763 - acc: 0.9340 - val_loss: 0.4497 - val_acc: 0.8646\n",
            "Epoch 30/30\n",
            "553/554 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9367"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r554/554 [==============================] - 12s 22ms/step - loss: 0.2706 - acc: 0.9366 - val_loss: 0.4635 - val_acc: 0.8656\n"
          ]
        }
      ],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nj-cHeMB18yc"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H77Ll-Cw1uEo"
      },
      "outputs": [],
      "source": [
        "#Let's load the best model obtained during training\n",
        "best_model = keras.models.load_model(\"best_model2.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfT8rzqE1xjN",
        "outputId": "42d647f9-afb4-4942-a616-51698540a0b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185/185 - 5s - loss: 0.3562 - accuracy: 0.8873 - 5s/epoch - 27ms/step\n",
            "Model accuracy:  0.8872905969619751\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4sjcUDC1zur",
        "outputId": "3e678c17-81eb-46ee-950c-85a5aaeb62c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185/185 [==============================] - 5s 25ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "7Bo6xYGriQoA",
        "outputId": "3b8fa43c-dbbe-4f8e-a5d9-95e7d163c1c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-40-1464592c3a2e>:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e167c4760>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzmEXuU3kH0O"
      },
      "source": [
        "# Columbia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClSsGe_WkMc-"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(columbia['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef9F42ZnkMpj",
        "outputId": "6da2b100-284e-4450-d78e-20c6809422fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...  949    6   61]\n",
            " [   0    0    0 ...   94  802  282]\n",
            " [   0    0    0 ... 1888  194  116]\n",
            " ...\n",
            " [   0    0    0 ...  369 2314  501]\n",
            " [   0    0    0 ...    0    0    0]\n",
            " [   0    0    0 ...   61  303  937]]\n",
            "19650 6550 19650 6550\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(columbia[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(columbia[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efz1tbmukMz1",
        "outputId": "8795ebbe-88f1-41ab-99f0-011f0fb8e896"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.6535\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72840, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 88s 133ms/step - loss: 0.7845 - accuracy: 0.6535 - val_loss: 0.6365 - val_accuracy: 0.7284\n",
            "Epoch 2/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.7584\n",
            "Epoch 2: val_accuracy improved from 0.72840 to 0.76840, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 79s 129ms/step - loss: 0.5845 - accuracy: 0.7584 - val_loss: 0.5459 - val_accuracy: 0.7684\n",
            "Epoch 3/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.8089\n",
            "Epoch 3: val_accuracy improved from 0.76840 to 0.81466, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 79s 129ms/step - loss: 0.4871 - accuracy: 0.8089 - val_loss: 0.4848 - val_accuracy: 0.8147\n",
            "Epoch 4/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.4261 - accuracy: 0.8355\n",
            "Epoch 4: val_accuracy improved from 0.81466 to 0.82702, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 81s 131ms/step - loss: 0.4261 - accuracy: 0.8355 - val_loss: 0.4582 - val_accuracy: 0.8270\n",
            "Epoch 5/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.8518\n",
            "Epoch 5: val_accuracy improved from 0.82702 to 0.84107, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 81s 132ms/step - loss: 0.3909 - accuracy: 0.8518 - val_loss: 0.4144 - val_accuracy: 0.8411\n",
            "Epoch 6/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.8673\n",
            "Epoch 6: val_accuracy improved from 0.84107 to 0.84214, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 78s 126ms/step - loss: 0.3604 - accuracy: 0.8673 - val_loss: 0.4072 - val_accuracy: 0.8421\n",
            "Epoch 7/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.8739\n",
            "Epoch 7: val_accuracy improved from 0.84214 to 0.86183, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 85s 138ms/step - loss: 0.3440 - accuracy: 0.8739 - val_loss: 0.3853 - val_accuracy: 0.8618\n",
            "Epoch 8/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3244 - accuracy: 0.8821\n",
            "Epoch 8: val_accuracy improved from 0.86183 to 0.86672, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 78s 127ms/step - loss: 0.3244 - accuracy: 0.8821 - val_loss: 0.3792 - val_accuracy: 0.8667\n",
            "Epoch 9/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.8891\n",
            "Epoch 9: val_accuracy did not improve from 0.86672\n",
            "615/615 [==============================] - 80s 130ms/step - loss: 0.3090 - accuracy: 0.8891 - val_loss: 0.3684 - val_accuracy: 0.8612\n",
            "Epoch 10/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.8929\n",
            "Epoch 10: val_accuracy improved from 0.86672 to 0.87053, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 80s 129ms/step - loss: 0.2972 - accuracy: 0.8929 - val_loss: 0.3688 - val_accuracy: 0.8705\n",
            "Epoch 11/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8976\n",
            "Epoch 11: val_accuracy did not improve from 0.87053\n",
            "615/615 [==============================] - 83s 135ms/step - loss: 0.2922 - accuracy: 0.8976 - val_loss: 0.3821 - val_accuracy: 0.8678\n",
            "Epoch 12/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.8993\n",
            "Epoch 12: val_accuracy improved from 0.87053 to 0.87557, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 79s 129ms/step - loss: 0.2823 - accuracy: 0.8993 - val_loss: 0.3471 - val_accuracy: 0.8756\n",
            "Epoch 13/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.9044\n",
            "Epoch 13: val_accuracy did not improve from 0.87557\n",
            "615/615 [==============================] - 78s 127ms/step - loss: 0.2765 - accuracy: 0.9044 - val_loss: 0.3617 - val_accuracy: 0.8742\n",
            "Epoch 14/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2715 - accuracy: 0.9063\n",
            "Epoch 14: val_accuracy did not improve from 0.87557\n",
            "615/615 [==============================] - 85s 139ms/step - loss: 0.2715 - accuracy: 0.9063 - val_loss: 0.3738 - val_accuracy: 0.8739\n",
            "Epoch 15/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9100\n",
            "Epoch 15: val_accuracy improved from 0.87557 to 0.87786, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 78s 127ms/step - loss: 0.2653 - accuracy: 0.9100 - val_loss: 0.3552 - val_accuracy: 0.8779\n",
            "Epoch 16/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.9105\n",
            "Epoch 16: val_accuracy improved from 0.87786 to 0.88046, saving model to best_model2.hdf5\n",
            "615/615 [==============================] - 78s 126ms/step - loss: 0.2622 - accuracy: 0.9105 - val_loss: 0.3467 - val_accuracy: 0.8805\n",
            "Epoch 17/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.9133\n",
            "Epoch 17: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 82s 133ms/step - loss: 0.2550 - accuracy: 0.9133 - val_loss: 0.3546 - val_accuracy: 0.8795\n",
            "Epoch 18/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.9141\n",
            "Epoch 18: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 75s 123ms/step - loss: 0.2542 - accuracy: 0.9141 - val_loss: 0.3492 - val_accuracy: 0.8780\n",
            "Epoch 19/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9170\n",
            "Epoch 19: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 77s 126ms/step - loss: 0.2489 - accuracy: 0.9170 - val_loss: 0.3473 - val_accuracy: 0.8800\n",
            "Epoch 20/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.9172\n",
            "Epoch 20: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 75s 122ms/step - loss: 0.2436 - accuracy: 0.9172 - val_loss: 0.3492 - val_accuracy: 0.8797\n",
            "Epoch 21/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9166\n",
            "Epoch 21: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 81s 132ms/step - loss: 0.2451 - accuracy: 0.9166 - val_loss: 0.3582 - val_accuracy: 0.8803\n",
            "Epoch 22/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.9226\n",
            "Epoch 22: val_accuracy did not improve from 0.88046\n",
            "615/615 [==============================] - 75s 122ms/step - loss: 0.2384 - accuracy: 0.9226 - val_loss: 0.3613 - val_accuracy: 0.8765\n",
            "Epoch 23/30\n",
            "379/615 [=================>............] - ETA: 26s - loss: 0.2339 - accuracy: 0.9205"
          ]
        }
      ],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ5cIiSpkM71",
        "outputId": "9f82c441-5725-40f1-8027-69b37b11f07f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.9939 - acc: 0.6319"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 36s 53ms/step - loss: 0.9938 - acc: 0.6320 - val_loss: 0.7514 - val_acc: 0.7226\n",
            "Epoch 2/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.7491"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.6934 - acc: 0.7493 - val_loss: 0.6665 - val_acc: 0.7518\n",
            "Epoch 3/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.6299 - acc: 0.7670"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.6299 - acc: 0.7670 - val_loss: 0.6306 - val_acc: 0.7600\n",
            "Epoch 4/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.5878 - acc: 0.7845"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.5882 - acc: 0.7844 - val_loss: 0.6005 - val_acc: 0.7733\n",
            "Epoch 5/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.5617 - acc: 0.7977"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 22ms/step - loss: 0.5618 - acc: 0.7976 - val_loss: 0.6069 - val_acc: 0.7744\n",
            "Epoch 6/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.8066"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.5462 - acc: 0.8067 - val_loss: 0.5749 - val_acc: 0.7942\n",
            "Epoch 7/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.5339 - acc: 0.8181"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.5337 - acc: 0.8181 - val_loss: 0.5702 - val_acc: 0.8003\n",
            "Epoch 8/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.5223 - acc: 0.8195"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 18s 29ms/step - loss: 0.5222 - acc: 0.8195 - val_loss: 0.5597 - val_acc: 0.8061\n",
            "Epoch 9/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.5127 - acc: 0.8291"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 22ms/step - loss: 0.5125 - acc: 0.8293 - val_loss: 0.5569 - val_acc: 0.8043\n",
            "Epoch 10/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.8350"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.5006 - acc: 0.8350 - val_loss: 0.5615 - val_acc: 0.8031\n",
            "Epoch 11/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.4867 - acc: 0.8416"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.4866 - acc: 0.8416 - val_loss: 0.5470 - val_acc: 0.8034\n",
            "Epoch 12/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.8460"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.4711 - acc: 0.8459 - val_loss: 0.5431 - val_acc: 0.8098\n",
            "Epoch 13/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.4580 - acc: 0.8537"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.4581 - acc: 0.8535 - val_loss: 0.5349 - val_acc: 0.8202\n",
            "Epoch 14/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.4453 - acc: 0.8585"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.4454 - acc: 0.8585 - val_loss: 0.5288 - val_acc: 0.8264\n",
            "Epoch 15/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.4359 - acc: 0.8646"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 17s 28ms/step - loss: 0.4358 - acc: 0.8646 - val_loss: 0.5260 - val_acc: 0.8182\n",
            "Epoch 16/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8725"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 15s 24ms/step - loss: 0.4251 - acc: 0.8728 - val_loss: 0.5141 - val_acc: 0.8282\n",
            "Epoch 17/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8806"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.4046 - acc: 0.8806 - val_loss: 0.5146 - val_acc: 0.8278\n",
            "Epoch 18/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8881"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.3884 - acc: 0.8881 - val_loss: 0.5863 - val_acc: 0.7847\n",
            "Epoch 19/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.3735 - acc: 0.8940"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.3735 - acc: 0.8940 - val_loss: 0.4954 - val_acc: 0.8324\n",
            "Epoch 20/30\n",
            "615/615 [==============================] - ETA: 0s - loss: 0.3611 - acc: 0.8987"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.3611 - acc: 0.8987 - val_loss: 0.4711 - val_acc: 0.8511\n",
            "Epoch 21/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.3507 - acc: 0.9014"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.3506 - acc: 0.9014 - val_loss: 0.5125 - val_acc: 0.8400\n",
            "Epoch 22/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.9058"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.3399 - acc: 0.9058 - val_loss: 0.4942 - val_acc: 0.8467\n",
            "Epoch 23/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.3322 - acc: 0.9100"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.3321 - acc: 0.9100 - val_loss: 0.4674 - val_acc: 0.8551\n",
            "Epoch 24/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.9147"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.3220 - acc: 0.9148 - val_loss: 0.4789 - val_acc: 0.8553\n",
            "Epoch 25/30\n",
            "614/615 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.9179"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.3136 - acc: 0.9179 - val_loss: 0.4664 - val_acc: 0.8554\n",
            "Epoch 26/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.3045 - acc: 0.9236"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.3045 - acc: 0.9236 - val_loss: 0.4812 - val_acc: 0.8478\n",
            "Epoch 27/30\n",
            "612/615 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9254"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.2975 - acc: 0.9255 - val_loss: 0.4837 - val_acc: 0.8559\n",
            "Epoch 28/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.9291"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.2893 - acc: 0.9292 - val_loss: 0.6494 - val_acc: 0.7791\n",
            "Epoch 29/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.9326"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 16s 26ms/step - loss: 0.2833 - acc: 0.9326 - val_loss: 0.4944 - val_acc: 0.8554\n",
            "Epoch 30/30\n",
            "613/615 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9358"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r615/615 [==============================] - 14s 23ms/step - loss: 0.2755 - acc: 0.9358 - val_loss: 0.5219 - val_acc: 0.8540\n"
          ]
        }
      ],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYEGw07g2iFz",
        "outputId": "dd863510-01b4-4ecf-8221-ed76bfcf4c30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "205/205 - 5s - loss: 1.8788 - accuracy: 0.5137 - 5s/epoch - 23ms/step\n",
            "Model accuracy:  0.5137404799461365\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShLw0tux2kja",
        "outputId": "46e7d90c-6474-4774-89b5-f15a92a88bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "205/205 [==============================] - 5s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "Un7EICp1kNCE",
        "outputId": "c309ee28-4009-45ac-f47f-3df4057c1ff2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-47-1464592c3a2e>:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e185be700>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8Qd5Hskklo"
      },
      "source": [
        "# Uchicago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa9hZIeikwzh"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(uchicago['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb5WQK-skw9f",
        "outputId": "7feb899e-76f7-4ba8-c19f-d9d08674c576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...    0 1140  537]\n",
            " [   0    0    0 ...    1  652   67]\n",
            " [   0    0    0 ...    0 1916  695]\n",
            " ...\n",
            " [   0    0    0 ...    0    0   95]\n",
            " [   0    0    0 ... 3131  733  301]\n",
            " [   0    0    0 ...  261   16  266]]\n",
            "19157 6386 19157 6386\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(uchicago[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(uchicago[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spiD0INckxGX",
        "outputId": "fb648fbc-b8d2-4a72-d6da-ea9eb775b3f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.7392 - accuracy: 0.6852\n",
            "Epoch 1: val_accuracy improved from -inf to 0.76605, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 97s 155ms/step - loss: 0.7392 - accuracy: 0.6852 - val_loss: 0.5927 - val_accuracy: 0.7661\n",
            "Epoch 2/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.7879\n",
            "Epoch 2: val_accuracy improved from 0.76605 to 0.81647, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 90s 150ms/step - loss: 0.5221 - accuracy: 0.7879 - val_loss: 0.4739 - val_accuracy: 0.8165\n",
            "Epoch 3/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.8302\n",
            "Epoch 3: val_accuracy improved from 0.81647 to 0.83934, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 152ms/step - loss: 0.4360 - accuracy: 0.8302 - val_loss: 0.4207 - val_accuracy: 0.8393\n",
            "Epoch 4/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8516\n",
            "Epoch 4: val_accuracy improved from 0.83934 to 0.84998, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 90s 151ms/step - loss: 0.3914 - accuracy: 0.8516 - val_loss: 0.4037 - val_accuracy: 0.8500\n",
            "Epoch 5/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8663\n",
            "Epoch 5: val_accuracy improved from 0.84998 to 0.86627, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 89s 148ms/step - loss: 0.3605 - accuracy: 0.8663 - val_loss: 0.3674 - val_accuracy: 0.8663\n",
            "Epoch 6/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8744\n",
            "Epoch 6: val_accuracy improved from 0.86627 to 0.86752, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 151ms/step - loss: 0.3395 - accuracy: 0.8744 - val_loss: 0.3600 - val_accuracy: 0.8675\n",
            "Epoch 7/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3220 - accuracy: 0.8824\n",
            "Epoch 7: val_accuracy improved from 0.86752 to 0.86862, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 88s 148ms/step - loss: 0.3220 - accuracy: 0.8824 - val_loss: 0.3708 - val_accuracy: 0.8686\n",
            "Epoch 8/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3044 - accuracy: 0.8899\n",
            "Epoch 8: val_accuracy improved from 0.86862 to 0.87974, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 152ms/step - loss: 0.3044 - accuracy: 0.8899 - val_loss: 0.3357 - val_accuracy: 0.8797\n",
            "Epoch 9/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8954\n",
            "Epoch 9: val_accuracy improved from 0.87974 to 0.88021, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 151ms/step - loss: 0.2917 - accuracy: 0.8954 - val_loss: 0.3440 - val_accuracy: 0.8802\n",
            "Epoch 10/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.8984\n",
            "Epoch 10: val_accuracy did not improve from 0.88021\n",
            "599/599 [==============================] - 89s 148ms/step - loss: 0.2856 - accuracy: 0.8984 - val_loss: 0.3433 - val_accuracy: 0.8791\n",
            "Epoch 11/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.9024\n",
            "Epoch 11: val_accuracy improved from 0.88021 to 0.88757, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 152ms/step - loss: 0.2755 - accuracy: 0.9024 - val_loss: 0.3257 - val_accuracy: 0.8876\n",
            "Epoch 12/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.9067\n",
            "Epoch 12: val_accuracy did not improve from 0.88757\n",
            "599/599 [==============================] - 89s 148ms/step - loss: 0.2705 - accuracy: 0.9067 - val_loss: 0.3324 - val_accuracy: 0.8837\n",
            "Epoch 13/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9068\n",
            "Epoch 13: val_accuracy did not improve from 0.88757\n",
            "599/599 [==============================] - 91s 152ms/step - loss: 0.2673 - accuracy: 0.9068 - val_loss: 0.3437 - val_accuracy: 0.8837\n",
            "Epoch 14/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2647 - accuracy: 0.9079\n",
            "Epoch 14: val_accuracy did not improve from 0.88757\n",
            "599/599 [==============================] - 89s 148ms/step - loss: 0.2647 - accuracy: 0.9079 - val_loss: 0.3279 - val_accuracy: 0.8862\n",
            "Epoch 15/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.9096\n",
            "Epoch 15: val_accuracy did not improve from 0.88757\n",
            "599/599 [==============================] - 90s 151ms/step - loss: 0.2624 - accuracy: 0.9096 - val_loss: 0.3269 - val_accuracy: 0.8876\n",
            "Epoch 16/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.9100\n",
            "Epoch 16: val_accuracy improved from 0.88757 to 0.89054, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 91s 151ms/step - loss: 0.2596 - accuracy: 0.9100 - val_loss: 0.3236 - val_accuracy: 0.8905\n",
            "Epoch 17/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.9119\n",
            "Epoch 17: val_accuracy did not improve from 0.89054\n",
            "599/599 [==============================] - 88s 147ms/step - loss: 0.2560 - accuracy: 0.9119 - val_loss: 0.3446 - val_accuracy: 0.8860\n",
            "Epoch 18/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.9133\n",
            "Epoch 18: val_accuracy did not improve from 0.89054\n",
            "599/599 [==============================] - 90s 151ms/step - loss: 0.2516 - accuracy: 0.9133 - val_loss: 0.3477 - val_accuracy: 0.8868\n",
            "Epoch 19/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.9119\n",
            "Epoch 19: val_accuracy did not improve from 0.89054\n",
            "599/599 [==============================] - 90s 150ms/step - loss: 0.2552 - accuracy: 0.9119 - val_loss: 0.3341 - val_accuracy: 0.8899\n",
            "Epoch 20/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9151\n",
            "Epoch 20: val_accuracy improved from 0.89054 to 0.89179, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 89s 149ms/step - loss: 0.2477 - accuracy: 0.9151 - val_loss: 0.3301 - val_accuracy: 0.8918\n",
            "Epoch 21/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.9163\n",
            "Epoch 21: val_accuracy improved from 0.89179 to 0.89242, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 89s 149ms/step - loss: 0.2451 - accuracy: 0.9163 - val_loss: 0.3307 - val_accuracy: 0.8924\n",
            "Epoch 22/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.9151\n",
            "Epoch 22: val_accuracy improved from 0.89242 to 0.89289, saving model to best_model2.hdf5\n",
            "599/599 [==============================] - 90s 150ms/step - loss: 0.2419 - accuracy: 0.9151 - val_loss: 0.3298 - val_accuracy: 0.8929\n",
            "Epoch 23/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.9182\n",
            "Epoch 23: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 93s 156ms/step - loss: 0.2416 - accuracy: 0.9182 - val_loss: 0.3497 - val_accuracy: 0.8888\n",
            "Epoch 24/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9184\n",
            "Epoch 24: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 89s 148ms/step - loss: 0.2377 - accuracy: 0.9184 - val_loss: 0.3404 - val_accuracy: 0.8916\n",
            "Epoch 25/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9203\n",
            "Epoch 25: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 89s 149ms/step - loss: 0.2341 - accuracy: 0.9203 - val_loss: 0.3310 - val_accuracy: 0.8920\n",
            "Epoch 26/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9176\n",
            "Epoch 26: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 91s 153ms/step - loss: 0.2398 - accuracy: 0.9176 - val_loss: 0.3350 - val_accuracy: 0.8910\n",
            "Epoch 27/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9186\n",
            "Epoch 27: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 88s 147ms/step - loss: 0.2375 - accuracy: 0.9186 - val_loss: 0.3317 - val_accuracy: 0.8902\n",
            "Epoch 28/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.9185\n",
            "Epoch 28: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 88s 147ms/step - loss: 0.2339 - accuracy: 0.9185 - val_loss: 0.3319 - val_accuracy: 0.8915\n",
            "Epoch 29/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9210\n",
            "Epoch 29: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 93s 156ms/step - loss: 0.2341 - accuracy: 0.9210 - val_loss: 0.3381 - val_accuracy: 0.8901\n",
            "Epoch 30/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.9215\n",
            "Epoch 30: val_accuracy did not improve from 0.89289\n",
            "599/599 [==============================] - 91s 152ms/step - loss: 0.2303 - accuracy: 0.9215 - val_loss: 0.3387 - val_accuracy: 0.8901\n"
          ]
        }
      ],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGOZYpPlkxQi",
        "outputId": "415822ec-2e98-4ac5-e448-c8bea1a88975"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.9843 - acc: 0.6349"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 15s 24ms/step - loss: 0.9841 - acc: 0.6350 - val_loss: 0.7623 - val_acc: 0.7261\n",
            "Epoch 2/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.6652 - acc: 0.7547"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.6652 - acc: 0.7548 - val_loss: 0.6178 - val_acc: 0.7733\n",
            "Epoch 3/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.5922 - acc: 0.7828"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 26ms/step - loss: 0.5922 - acc: 0.7827 - val_loss: 0.5843 - val_acc: 0.7944\n",
            "Epoch 4/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.5598 - acc: 0.7984"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 23ms/step - loss: 0.5598 - acc: 0.7984 - val_loss: 0.5694 - val_acc: 0.7967\n",
            "Epoch 5/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.5411 - acc: 0.8086"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 23ms/step - loss: 0.5411 - acc: 0.8086 - val_loss: 0.5621 - val_acc: 0.7861\n",
            "Epoch 6/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.5265 - acc: 0.8133"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 23ms/step - loss: 0.5265 - acc: 0.8133 - val_loss: 0.5445 - val_acc: 0.8000\n",
            "Epoch 7/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.5154 - acc: 0.8187"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 26ms/step - loss: 0.5155 - acc: 0.8186 - val_loss: 0.5450 - val_acc: 0.7939\n",
            "Epoch 8/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.5047 - acc: 0.8226"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 26ms/step - loss: 0.5047 - acc: 0.8225 - val_loss: 0.5398 - val_acc: 0.7982\n",
            "Epoch 9/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.4940 - acc: 0.8263"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.4937 - acc: 0.8264 - val_loss: 0.5317 - val_acc: 0.8107\n",
            "Epoch 10/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.8311"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 23ms/step - loss: 0.4810 - acc: 0.8311 - val_loss: 0.5317 - val_acc: 0.8127\n",
            "Epoch 11/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8381"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.4675 - acc: 0.8380 - val_loss: 0.5271 - val_acc: 0.8085\n",
            "Epoch 12/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.4538 - acc: 0.8463"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.4538 - acc: 0.8463 - val_loss: 0.5264 - val_acc: 0.8138\n",
            "Epoch 13/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.4408 - acc: 0.8515"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.4408 - acc: 0.8515 - val_loss: 0.5170 - val_acc: 0.8141\n",
            "Epoch 14/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.4287 - acc: 0.8569"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.4287 - acc: 0.8569 - val_loss: 0.4991 - val_acc: 0.8263\n",
            "Epoch 15/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8623"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.4172 - acc: 0.8624 - val_loss: 0.5062 - val_acc: 0.8232\n",
            "Epoch 16/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8660"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.4099 - acc: 0.8660 - val_loss: 0.5008 - val_acc: 0.8284\n",
            "Epoch 17/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8681"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.3998 - acc: 0.8680 - val_loss: 0.5288 - val_acc: 0.8122\n",
            "Epoch 18/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3934 - acc: 0.8724"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.3934 - acc: 0.8724 - val_loss: 0.5086 - val_acc: 0.8271\n",
            "Epoch 19/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3838 - acc: 0.8781"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 23ms/step - loss: 0.3838 - acc: 0.8781 - val_loss: 0.5107 - val_acc: 0.8229\n",
            "Epoch 20/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3748 - acc: 0.8825"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.3748 - acc: 0.8825 - val_loss: 0.5023 - val_acc: 0.8292\n",
            "Epoch 21/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.3665 - acc: 0.8855"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.3670 - acc: 0.8855 - val_loss: 0.5113 - val_acc: 0.8257\n",
            "Epoch 22/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3596 - acc: 0.8894"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.3596 - acc: 0.8894 - val_loss: 0.5633 - val_acc: 0.8047\n",
            "Epoch 23/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8947"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.3515 - acc: 0.8946 - val_loss: 0.5219 - val_acc: 0.8310\n",
            "Epoch 24/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3435 - acc: 0.8993"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 26ms/step - loss: 0.3435 - acc: 0.8993 - val_loss: 0.5115 - val_acc: 0.8313\n",
            "Epoch 25/30\n",
            "598/599 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.9042"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 15s 25ms/step - loss: 0.3362 - acc: 0.9042 - val_loss: 0.5181 - val_acc: 0.8257\n",
            "Epoch 26/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.9085"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.3272 - acc: 0.9083 - val_loss: 0.5350 - val_acc: 0.8298\n",
            "Epoch 27/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.9124"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 14s 24ms/step - loss: 0.3212 - acc: 0.9124 - val_loss: 0.5215 - val_acc: 0.8382\n",
            "Epoch 28/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.9186"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 15s 25ms/step - loss: 0.3120 - acc: 0.9187 - val_loss: 0.5238 - val_acc: 0.8335\n",
            "Epoch 29/30\n",
            "599/599 [==============================] - ETA: 0s - loss: 0.3043 - acc: 0.9216"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.3043 - acc: 0.9216 - val_loss: 0.5784 - val_acc: 0.8050\n",
            "Epoch 30/30\n",
            "597/599 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9268"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r599/599 [==============================] - 16s 27ms/step - loss: 0.2974 - acc: 0.9268 - val_loss: 0.5263 - val_acc: 0.8395\n"
          ]
        }
      ],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_ZOrHjq2nD2",
        "outputId": "00e5f7e1-60ed-48a3-df09-a2c2d2399aee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/200 - 7s - loss: 1.8498 - accuracy: 0.5326 - 7s/epoch - 34ms/step\n",
            "Model accuracy:  0.5325712561607361\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dILPs2qn2nUV",
        "outputId": "4e84f723-1007-4bc4-9b10-2b402f042c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 5s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "Q9KQ9JIAlEdD",
        "outputId": "f872a083-6063-4a75-c650-e56c10ebd40d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-54-1464592c3a2e>:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e167c4d60>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOuLwf3xlIF9"
      },
      "source": [
        "# **Cluster 2 - Princeton, Brown, Dartmouth**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xw1lLcAlEwa"
      },
      "outputs": [],
      "source": [
        "princeton = posts.loc[posts['subreddit_name'] == 'princeton']\n",
        "brown = posts.loc[posts['subreddit_name'] == 'brownu']\n",
        "dartmouth = posts.loc[posts['subreddit_name'] == 'dartmouth']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkbGB1JllmXV"
      },
      "source": [
        "# Princeton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHmg3xqBlv9r"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(princeton['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcaANsBklwJ_",
        "outputId": "3d0ff8a4-d567-4a3a-fb61-28f050169060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...  136  213 1269]\n",
            " [   0    0    0 ...  293  890   52]\n",
            " [   0    0    0 ...  195 1570  864]\n",
            " ...\n",
            " [   0    0    0 ...  210   75  916]\n",
            " [   0    0    0 ...   88  679   37]\n",
            " [   0    0    0 ...  790  760   40]]\n",
            "6619 2207 6619 2207\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(princeton[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(princeton[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIXacKc4lwR7",
        "outputId": "3d596bff-9a66-4e04-e1c5-24b1ad3e3ad5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.7989 - accuracy: 0.6771\n",
            "Epoch 1: val_accuracy improved from -inf to 0.72859, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 36s 148ms/step - loss: 0.7989 - accuracy: 0.6771 - val_loss: 0.7017 - val_accuracy: 0.7286\n",
            "Epoch 2/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.6431 - accuracy: 0.7362\n",
            "Epoch 2: val_accuracy improved from 0.72859 to 0.76756, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 34s 166ms/step - loss: 0.6431 - accuracy: 0.7362 - val_loss: 0.5853 - val_accuracy: 0.7676\n",
            "Epoch 3/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.5494 - accuracy: 0.7846\n",
            "Epoch 3: val_accuracy improved from 0.76756 to 0.77889, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 30s 143ms/step - loss: 0.5494 - accuracy: 0.7846 - val_loss: 0.5518 - val_accuracy: 0.7789\n",
            "Epoch 4/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8099\n",
            "Epoch 4: val_accuracy improved from 0.77889 to 0.79882, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 32s 152ms/step - loss: 0.4813 - accuracy: 0.8099 - val_loss: 0.5195 - val_accuracy: 0.7988\n",
            "Epoch 5/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.8249\n",
            "Epoch 5: val_accuracy improved from 0.79882 to 0.80199, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 31s 152ms/step - loss: 0.4415 - accuracy: 0.8249 - val_loss: 0.5293 - val_accuracy: 0.8020\n",
            "Epoch 6/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3981 - accuracy: 0.8489\n",
            "Epoch 6: val_accuracy improved from 0.80199 to 0.80970, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 31s 149ms/step - loss: 0.3981 - accuracy: 0.8489 - val_loss: 0.5550 - val_accuracy: 0.8097\n",
            "Epoch 7/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.8606\n",
            "Epoch 7: val_accuracy improved from 0.80970 to 0.82465, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 31s 148ms/step - loss: 0.3605 - accuracy: 0.8606 - val_loss: 0.4842 - val_accuracy: 0.8246\n",
            "Epoch 8/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8769\n",
            "Epoch 8: val_accuracy improved from 0.82465 to 0.82782, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 29s 139ms/step - loss: 0.3329 - accuracy: 0.8769 - val_loss: 0.4829 - val_accuracy: 0.8278\n",
            "Epoch 9/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8859\n",
            "Epoch 9: val_accuracy improved from 0.82782 to 0.83054, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 32s 156ms/step - loss: 0.3144 - accuracy: 0.8859 - val_loss: 0.4810 - val_accuracy: 0.8305\n",
            "Epoch 10/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8956\n",
            "Epoch 10: val_accuracy improved from 0.83054 to 0.83326, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 30s 146ms/step - loss: 0.2917 - accuracy: 0.8956 - val_loss: 0.4733 - val_accuracy: 0.8333\n",
            "Epoch 11/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.9027\n",
            "Epoch 11: val_accuracy did not improve from 0.83326\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.2758 - accuracy: 0.9027 - val_loss: 0.5108 - val_accuracy: 0.8233\n",
            "Epoch 12/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9059\n",
            "Epoch 12: val_accuracy did not improve from 0.83326\n",
            "207/207 [==============================] - 29s 139ms/step - loss: 0.2579 - accuracy: 0.9059 - val_loss: 0.5049 - val_accuracy: 0.8324\n",
            "Epoch 13/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9124\n",
            "Epoch 13: val_accuracy did not improve from 0.83326\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.2491 - accuracy: 0.9124 - val_loss: 0.4709 - val_accuracy: 0.8296\n",
            "Epoch 14/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.9189\n",
            "Epoch 14: val_accuracy improved from 0.83326 to 0.83734, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 30s 146ms/step - loss: 0.2327 - accuracy: 0.9189 - val_loss: 0.5051 - val_accuracy: 0.8373\n",
            "Epoch 15/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9201\n",
            "Epoch 15: val_accuracy did not improve from 0.83734\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.2278 - accuracy: 0.9201 - val_loss: 0.5126 - val_accuracy: 0.8373\n",
            "Epoch 16/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.9220\n",
            "Epoch 16: val_accuracy improved from 0.83734 to 0.84413, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.2260 - accuracy: 0.9220 - val_loss: 0.4945 - val_accuracy: 0.8441\n",
            "Epoch 17/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9254\n",
            "Epoch 17: val_accuracy did not improve from 0.84413\n",
            "207/207 [==============================] - 29s 139ms/step - loss: 0.2185 - accuracy: 0.9254 - val_loss: 0.5432 - val_accuracy: 0.8287\n",
            "Epoch 18/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9314\n",
            "Epoch 18: val_accuracy improved from 0.84413 to 0.84549, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 0.2060 - accuracy: 0.9314 - val_loss: 0.4922 - val_accuracy: 0.8455\n",
            "Epoch 19/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9287\n",
            "Epoch 19: val_accuracy did not improve from 0.84549\n",
            "207/207 [==============================] - 31s 147ms/step - loss: 0.2104 - accuracy: 0.9287 - val_loss: 0.5084 - val_accuracy: 0.8419\n",
            "Epoch 20/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9316\n",
            "Epoch 20: val_accuracy did not improve from 0.84549\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.2013 - accuracy: 0.9316 - val_loss: 0.5260 - val_accuracy: 0.8382\n",
            "Epoch 21/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1957 - accuracy: 0.9328\n",
            "Epoch 21: val_accuracy did not improve from 0.84549\n",
            "207/207 [==============================] - 29s 140ms/step - loss: 0.1957 - accuracy: 0.9328 - val_loss: 0.4947 - val_accuracy: 0.8437\n",
            "Epoch 22/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9384\n",
            "Epoch 22: val_accuracy did not improve from 0.84549\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.1848 - accuracy: 0.9384 - val_loss: 0.5164 - val_accuracy: 0.8437\n",
            "Epoch 23/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.9355\n",
            "Epoch 23: val_accuracy did not improve from 0.84549\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.1898 - accuracy: 0.9355 - val_loss: 0.5427 - val_accuracy: 0.8364\n",
            "Epoch 24/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9397\n",
            "Epoch 24: val_accuracy improved from 0.84549 to 0.85048, saving model to best_model2.hdf5\n",
            "207/207 [==============================] - 30s 146ms/step - loss: 0.1796 - accuracy: 0.9397 - val_loss: 0.5270 - val_accuracy: 0.8505\n",
            "Epoch 25/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9368\n",
            "Epoch 25: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.1806 - accuracy: 0.9368 - val_loss: 0.4955 - val_accuracy: 0.8405\n",
            "Epoch 26/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9382\n",
            "Epoch 26: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 29s 139ms/step - loss: 0.1772 - accuracy: 0.9382 - val_loss: 0.4955 - val_accuracy: 0.8437\n",
            "Epoch 27/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9430\n",
            "Epoch 27: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 32s 156ms/step - loss: 0.1701 - accuracy: 0.9430 - val_loss: 0.4977 - val_accuracy: 0.8496\n",
            "Epoch 28/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.9432\n",
            "Epoch 28: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 30s 147ms/step - loss: 0.1674 - accuracy: 0.9432 - val_loss: 0.5857 - val_accuracy: 0.8469\n",
            "Epoch 29/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.9423\n",
            "Epoch 29: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 30s 146ms/step - loss: 0.1685 - accuracy: 0.9423 - val_loss: 0.5285 - val_accuracy: 0.8500\n",
            "Epoch 30/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.1702 - accuracy: 0.9415\n",
            "Epoch 30: val_accuracy did not improve from 0.85048\n",
            "207/207 [==============================] - 29s 138ms/step - loss: 0.1702 - accuracy: 0.9415 - val_loss: 0.4728 - val_accuracy: 0.8473\n"
          ]
        }
      ],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9eovRhpFlwZM",
        "outputId": "e41b5dd0-c6f0-4b70-dc8c-365ad3dcd856"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 1.1610 - acc: 0.6506"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 6s 25ms/step - loss: 1.1570 - acc: 0.6516 - val_loss: 0.8799 - val_acc: 0.6661\n",
            "Epoch 2/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.8106 - acc: 0.6876"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.8106 - acc: 0.6876 - val_loss: 0.6991 - val_acc: 0.7802\n",
            "Epoch 3/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.6432 - acc: 0.7928"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 6s 28ms/step - loss: 0.6432 - acc: 0.7924 - val_loss: 0.6130 - val_acc: 0.8065\n",
            "Epoch 4/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.5827 - acc: 0.8187"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 6s 27ms/step - loss: 0.5827 - acc: 0.8187 - val_loss: 0.5782 - val_acc: 0.8115\n",
            "Epoch 5/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.5486 - acc: 0.8275"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 26ms/step - loss: 0.5486 - acc: 0.8275 - val_loss: 0.5564 - val_acc: 0.8160\n",
            "Epoch 6/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.8348"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 6s 30ms/step - loss: 0.5231 - acc: 0.8350 - val_loss: 0.5590 - val_acc: 0.8101\n",
            "Epoch 7/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.8380"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.5028 - acc: 0.8379 - val_loss: 0.5374 - val_acc: 0.8156\n",
            "Epoch 8/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.4853 - acc: 0.8447"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4851 - acc: 0.8445 - val_loss: 0.5522 - val_acc: 0.8133\n",
            "Epoch 9/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4730 - acc: 0.8456"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4730 - acc: 0.8456 - val_loss: 0.5366 - val_acc: 0.8192\n",
            "Epoch 10/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4624 - acc: 0.8507"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4624 - acc: 0.8507 - val_loss: 0.5406 - val_acc: 0.8151\n",
            "Epoch 11/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8556"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4514 - acc: 0.8556 - val_loss: 0.5363 - val_acc: 0.8188\n",
            "Epoch 12/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.4427 - acc: 0.8536"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 7s 32ms/step - loss: 0.4431 - acc: 0.8536 - val_loss: 0.5415 - val_acc: 0.8206\n",
            "Epoch 13/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4340 - acc: 0.8596"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4340 - acc: 0.8596 - val_loss: 0.5484 - val_acc: 0.8256\n",
            "Epoch 14/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.4254 - acc: 0.8630"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.4255 - acc: 0.8630 - val_loss: 0.5467 - val_acc: 0.8233\n",
            "Epoch 15/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.4155 - acc: 0.8692"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.4154 - acc: 0.8692 - val_loss: 0.5690 - val_acc: 0.8206\n",
            "Epoch 16/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.4055 - acc: 0.8717"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 7s 32ms/step - loss: 0.4055 - acc: 0.8717 - val_loss: 0.5451 - val_acc: 0.8219\n",
            "Epoch 17/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.3960 - acc: 0.8739"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3960 - acc: 0.8738 - val_loss: 0.5550 - val_acc: 0.8274\n",
            "Epoch 18/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8783"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3893 - acc: 0.8779 - val_loss: 0.5654 - val_acc: 0.8224\n",
            "Epoch 19/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3801 - acc: 0.8840"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3801 - acc: 0.8840 - val_loss: 0.5692 - val_acc: 0.8165\n",
            "Epoch 20/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.8887"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 24ms/step - loss: 0.3716 - acc: 0.8891 - val_loss: 0.5764 - val_acc: 0.8237\n",
            "Epoch 21/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8928"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3645 - acc: 0.8924 - val_loss: 0.5829 - val_acc: 0.8165\n",
            "Epoch 22/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.8973"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3563 - acc: 0.8973 - val_loss: 0.5894 - val_acc: 0.8179\n",
            "Epoch 23/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.3481 - acc: 0.9040"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3483 - acc: 0.9038 - val_loss: 0.5974 - val_acc: 0.8206\n",
            "Epoch 24/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3388 - acc: 0.9080"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3388 - acc: 0.9080 - val_loss: 0.6118 - val_acc: 0.8201\n",
            "Epoch 25/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3307 - acc: 0.9131"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3307 - acc: 0.9131 - val_loss: 0.6468 - val_acc: 0.8156\n",
            "Epoch 26/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.3220 - acc: 0.9157"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3220 - acc: 0.9157 - val_loss: 0.6264 - val_acc: 0.8151\n",
            "Epoch 27/30\n",
            "205/207 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.9198"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3146 - acc: 0.9201 - val_loss: 0.6316 - val_acc: 0.8174\n",
            "Epoch 28/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9238"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 5s 25ms/step - loss: 0.3050 - acc: 0.9233 - val_loss: 0.6716 - val_acc: 0.8029\n",
            "Epoch 29/30\n",
            "206/207 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9302"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207/207 [==============================] - 7s 32ms/step - loss: 0.2974 - acc: 0.9300 - val_loss: 0.6333 - val_acc: 0.7970\n",
            "Epoch 30/30\n",
            "207/207 [==============================] - ETA: 0s - loss: 0.2882 - acc: 0.9328"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r207/207 [==============================] - 5s 25ms/step - loss: 0.2882 - acc: 0.9328 - val_loss: 0.6686 - val_acc: 0.8206\n"
          ]
        }
      ],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=30,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iPqzH7H12t2f",
        "outputId": "1c1f13cf-af9c-4432-9319-3d087191e201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 - 2s - loss: 1.8382 - accuracy: 0.5374 - 2s/epoch - 24ms/step\n",
            "Model accuracy:  0.5373810529708862\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D9UJZRUa2uLi",
        "outputId": "006b70c2-73d0-453c-d7b1-79d65ca7ded7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 2s 27ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y3LRsayomCqX",
        "outputId": "d1b1114b-cba3-4992-cf0b-a76b85459928"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-62-1464592c3a2e>:8: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e1ce2afa0>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhdVNlmFmHuX"
      },
      "source": [
        "# B. Brown University"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mVT1XcVdmM3g"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(brown['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2vbidNBVmNDW",
        "outputId": "39d83cab-2f02-438b-f134-5aa9a9dc15ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ... 1856 3329 1586]\n",
            " [   0    0    0 ...  161 4227 3723]\n",
            " [   0    0    0 ...   53 1773   94]\n",
            " ...\n",
            " [   0    0    0 ...  179   12   19]\n",
            " [   0    0    0 ...  597   73 1025]\n",
            " [   0    0    0 ...  621   10   19]]\n",
            "9588 3196 9588 3196\n"
          ]
        }
      ],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(brown[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(brown[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPQy4EgEmNPG"
      },
      "outputs": [],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5-mAYlbImNY2"
      },
      "outputs": [],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "liqU6fbJ2zqB"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VsK74b6k2z9l"
      },
      "outputs": [],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7KwIm3t2mNiU"
      },
      "outputs": [],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njR6Z54Smh67"
      },
      "source": [
        "# C. Dartmouth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KZQZN9gZmN4M"
      },
      "outputs": [],
      "source": [
        "#convert sentiments to numerical value\n",
        "labels = np.array(dartmouth['sentiment'])\n",
        "y = []\n",
        "for i in range(len(labels)):\n",
        "    if labels[i] == 'neutral':\n",
        "        y.append(0)\n",
        "    if labels[i] == 'negative':\n",
        "        y.append(1)\n",
        "    if labels[i] == 'positive':\n",
        "        y.append(2)\n",
        "\n",
        "y = np.array(y)\n",
        "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
        "del y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WB-BQ7BXmOAQ"
      },
      "outputs": [],
      "source": [
        "#splitting\n",
        "max_words = 5000\n",
        "max_len = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(dartmouth[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(dartmouth[\"text\"])\n",
        "reddit_posts = pad_sequences(sequences, maxlen=max_len)\n",
        "print(reddit_posts)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reddit_posts, labels, random_state = 0)\n",
        "print (len(X_train),len(X_test),len(y_train),len(y_test)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf4goqe-mOCl"
      },
      "outputs": [],
      "source": [
        "#ltsm model\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
        "model.add(layers.Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#checkpoints enure the best metric is saved during training\n",
        "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zijYFCSWm13_"
      },
      "outputs": [],
      "source": [
        "#Try CNN implementation and compare \n",
        "from keras import regularizers\n",
        "model3 = Sequential()\n",
        "model3.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.MaxPooling1D(5))\n",
        "model3.add(layers.Conv1D(20, 6, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=2e-3, l2=2e-3),bias_regularizer=regularizers.l2(2e-3)))\n",
        "model3.add(layers.GlobalMaxPooling1D())\n",
        "model3.add(layers.Dense(3,activation='softmax'))\n",
        "model3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
        "checkpoint3 = ModelCheckpoint(\"best_model3.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
        "history = model3.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGPR0cHt27Hc"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
        "print('Model accuracy: ',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BStP9xd727ZC"
      },
      "outputs": [],
      "source": [
        "predictions = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Jg3CDGXm6w0"
      },
      "outputs": [],
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(y_test.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))\n",
        "\n",
        "import seaborn as sns\n",
        "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
        "#Normalizing\n",
        "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure(figsize = (15,15))\n",
        "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQr5KmJam6Cw"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}